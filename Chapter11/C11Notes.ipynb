{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 11 Survival Analysis and Censored Data\n",
        "\n",
        "* Both of these rely on time until an event occurs. Like time surviving once being diagnosed with cancer.\n",
        "\n",
        "* Problem can use survival analysis for when a certain threshold is reached then it becomes censored data.\n",
        "\n"
      ],
      "metadata": {
        "id": "RYhxUVddvk61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.1 Survival and Censoring Times\n",
        "\n",
        "* Survival time is when the patient dies or the subscription is canceled, called $T$. The Censoring time is when the patient leaves the study or the study ends, called $C$.\n",
        "  * $Y = min(T,C)$\n",
        "*$σ =  \\begin{cases}\n",
        "      0 & T ≤ C \\\\\n",
        "      1 & T > C\n",
        "   \\end{cases}$\n",
        "   * Thus $σ = 1$ we observe the survival else the censoring time\n",
        "* Therefore for $n$ observations we can find $n(Y, σ)$\n"
      ],
      "metadata": {
        "id": "LvmsxavgwaUD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.2 A Closer Look at Censoring\n",
        "* Must assume the censoring and survivor analysis are independent of each other.\n",
        "* Right Censoring $ T ≥ Y $\n",
        "* Left Censoring $ T ≤ Y $\n",
        "* Interval Censoring don't know the exact $T$ but rather an interval for $T$"
      ],
      "metadata": {
        "id": "NvyfnFBap2k4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.3 The Kaplan - Meier Survival Curve\n",
        "* $S(t) = Pr(T >t)$\n",
        "* This can be difficult to compute with the data having a mix of censored and survivor data.\n",
        "  * To fix this we fix $K$ unique death times $d_{1}..... d_{K}$ among non censored patients\n",
        "  * Let $q_{k}$ denote the amount of patients who died at $d_{k}$\n",
        "  * For $1 ... K$ we let $r_{k}$ denote the amount of at risk patients alive\n",
        "  * Use the total law of probability and some simplification. This gives us the Kaplan - Meier Survival Curve\n",
        "* $S(d_{k}) =Π_{j=1}^{k}(\\frac {(r_{j} - q_{j})}{r_{j}})$\n"
      ],
      "metadata": {
        "id": "I2if3t_Tt2XW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.4 The Log Rank Test\n",
        "* $ W = \\frac {X - μ}{\\sqrt{Var(X)}}$\n",
        "  * $ X = ∑_{k =1}^{K}q_{1k}$\n",
        "  * $μ = ∑_{k =1}^{K} \\frac {r_{1k}}{r_{k}}q_{k}$\n",
        "  * $Var(X) = ∑ _{k =1}^{K} \\frac {q_{k}(r_{1k}/r_{k})(1 -r_{1k}/r_{k})(r_{k} - q_{k})}{r_{k} - 1}$\n",
        "* Then run a p test to see if you can reject the null hypothesis"
      ],
      "metadata": {
        "id": "uIRmmvvVuR-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.5 Regression Model with a Survival Response\n",
        "* Tempting to use linear regression on the 11.1 pairs, however censored data will pose a problem."
      ],
      "metadata": {
        "id": "9_KWecMZ09s7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.5.1 The Hazard Function\n",
        "\n",
        "* Rate of death at a certain time t\n",
        "* $h(t) =  \\frac {f(t)}{S(t)}$ where\n",
        "  * $h(t)$ is the hazard function\n",
        "  * $f(t)$ probability density function\n",
        "  * $S(t)$ Survival function\n",
        "* Thus $ = f(y_{i}^{σ_{i}})S(y_{i}^{1- σ_{i}})$ so if the data is censored then $σ = 1$ so $Y = S(y_{i})$ and if it is not censored then $σ = 0$ thus $ Y= f(y_{i})$\n",
        "  * For n observations this would yield $L = Π_{i=1}^{n} f(y_{i}^{σ_{i}})S(y_{i}^{1- σ_{i}})$\n",
        "  * Can estimate $f(t)$ using the probability density function of the form $f(t) = λ exp(-λt)$. Then plug values for $λ$ that maximize $L$\n",
        "* We can use the above equations to calculate $S(t)$ and $f(t)$ and use an assumption that $h(t|x_{i}) = exp(β_{0} + Σ_{j=1}^{p}β_{j}x_{ij})$ Then we can find the $β_{0}...... β_{p}$ that maximize $L$. This isn't the best option as we have to make an assumption about the $h(t)$"
      ],
      "metadata": {
        "id": "QjHEHStu3VIo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.5.2 Proportional Hazards\n",
        "* $h(t|x_{i}) = h_{0}(t) + exp(Σ_{j=1}^{p}x_{ij}β_{j})$ where $h_{0}(t) is the baseline hazard\n",
        "* the baseline hazard is also unspecified which means it can take any form.\n"
      ],
      "metadata": {
        "id": "WOrZaOr35ZWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cox Proportional Hazard Model\n",
        "* We don't know $h_{0}(t)$ and can't just plug into $h(t|x_{i}$ into $L$ for likelihood to estimate $β = (β{1}....β_{p})$\n",
        "* Magic of Cox Proportional is it is possible to estimate $β$ without knowing $h_{0}(t)$\n",
        "* The $h_{0}(t)$ terms cancel in the deriving of the Cox Proportional Hazard. Thus it can be calculated without it.\n",
        "* Then compute the partial likelihood with the values of $β$ that maximize it.\n",
        "* Can then find p values, and confidence intervals like with linear regression and logistic regression. Can then reject or accept the null hypothesis and certain parameters."
      ],
      "metadata": {
        "id": "FKa-uwQ7cSLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Connection with Log Ranked Test\n",
        "* When performing the Cox Proportional Hazard Model test with a binary single predictor it is the same as the log test.\n",
        "* Normally have two options to test if there is a difference in survival times of two groups we can use Cox proportional hazard model to find the $β$ values then run a p test. See if we can reject the null hypothesis. OR run a log rank test. Both perform the same in this case."
      ],
      "metadata": {
        "id": "4yudjADaevQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Additional Details\n",
        "* No intercept in Cox since it is absorbed into $h_{0}(t)$\n",
        "* Can estimate $h_{0}(t)$ to discover $S(t)$ and can be implemented in Python.\n",
        "* Partial Likelihood isn't the full likelihood but estimates it rather well."
      ],
      "metadata": {
        "id": "iNur1q8zh2hu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.5.3 Example: Brain Cancer Data\n",
        "* Important to add all predictors as they can increase the accuracy of a model and its p values."
      ],
      "metadata": {
        "id": "5y1NivoxiXWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.6 Shrinkage of the Cox Model\n",
        "* Can add a $ λP(β)$ penalty to the end of the Cox Model.\n",
        "  * Can Pick $P(B) = Σ_{i=1}^{p}Β_{j}^{2}$ Ridge Regression\n",
        "  * or $P(B) = Σ_{i=1}^{p}|B_{j}|$ Lasso\n",
        "  * Lasso will take some coefficients to 0 while ridge will shrink all coefficients\n",
        "* We can use cross validation on the $λ$ to find the most efficient value.\n",
        "* However we can't break the data into test and train as the censoring alters this. Therefore we break the data into sets like high, medium, and low risk. Then use our predictor formula on each group and see how well it performs.\n",
        ""
      ],
      "metadata": {
        "id": "lRnRcxYGjnZo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.7 Additional Topics"
      ],
      "metadata": {
        "id": "43UaIbmhjqUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.7.1 Area Under the Curve for Survival Analysis\n",
        "* Gives a percentage based on two classes if it will be identified correctly."
      ],
      "metadata": {
        "id": "4eDCgEbYnzK6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.7.2 Choice of Time Scale\n",
        "* Must be careful defining time zero as it could be the day the disease was discovered, their birthday, age the disease came about etc."
      ],
      "metadata": {
        "id": "OZqBejy_prU0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.7.3 Time-Dependent Covariates\n",
        "* Takes the $n$ observation of predictor $p$ such that $x_{np}$ has a function of time thus $x_{np}(t)$. This seamlessly integrates with the cox formula."
      ],
      "metadata": {
        "id": "59EKGnE7qBIu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.7.4 Checking the Proportional Hazard Assumption\n",
        "* Should check to make sure the assumption holds when using this formula"
      ],
      "metadata": {
        "id": "NUZKcmaoq3-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.7.5 Survival Trees\n",
        "* Can make survival trees like in the regression and classification case.\n",
        "* Make trees that maximize the survival curves in the result daughter nodes\n",
        "* Can combine several trees to make a random survival forest."
      ],
      "metadata": {
        "id": "l3bao65nrp-I"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-ZfpMgJSsIgI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}