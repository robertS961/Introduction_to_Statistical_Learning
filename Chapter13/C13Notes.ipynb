{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 13 Multiple Testing\n",
        "\n",
        "* Null Hypothesis states the control group is the same as the experiment group.\n",
        "\n",
        "* We may wish to test many null hypotheses like rath than simply testing $H_0$ we might wish to test $H_{01},...., H_{0j}$ where $H_{0j}$ is the hypothesis that the j column's mice does not have a higher blood pressure than the control.\n",
        "\n",
        "* This chapter will go into contemporary and past methods to correctly test these hypothesis and understand the p values with them"
      ],
      "metadata": {
        "id": "kyWKvkvWb2s3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13.1 A Quick Review of Hypothesis Testing\n",
        "\n",
        "1. Is it true that the coefficients $B_j$ in a linear regression Y onto $X_1,.....,X_p$ equal 0?\n",
        "\n",
        "1. Is there a difference from the control to the test group?\n",
        "\n"
      ],
      "metadata": {
        "id": "e9--os6eb9nm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 13.1.1 Testing a Hypothesis\n",
        "\n",
        "1. Define the null and alternate hypothesis\n",
        "1. Construct a test statistics. Evidence against the null hypothesis\n",
        "1. Calculate the p statistics.\n",
        "1. Based on the value of the p statistics we reject or accept the null hypothesis.\n",
        "\n",
        "* Step 1: if we fail to reject $H_0$ it could be because it is true. OR our data sample was too small or missing important predictors.\n",
        "\n",
        "* Step 2: If the T statistic is large then it provides evidence for $H_a$ and if it is small then evidence for $H_0$.\n",
        "\n",
        "* Step 3: p value gives us context to if the T statistic is large enough. It gives us the probability of the observed being equal to or greater probability to what we are testing. Thus when we are testing the null hypothesis we want a small p value. Thus if we are just given a T value, we can't compute the p value. We need to know the expected value of T under $H_0$. This is what the p value gives us, a probability between 0 and 1, which is more easily interpreted.\n",
        "\n",
        "* Step 4: Different fields they use different thresholds for the p value to reject or accept the null hypothesis.\n"
      ],
      "metadata": {
        "id": "UiLMWq7sXAPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 13.1.2 Type 1 and Type 2 Errors.\n",
        "\n",
        "* Type 1 Error is Rejecting $H_0$ when it is indeed correct. Thus a false positive.\n",
        "\n",
        "* Type 1 Error Rate is the probability of incorrectly rejecting $H_0$\n",
        "\n",
        "* Type 2 Error is not rejecting $H_0$ when $H_0$ is false. Thus a false negative.\n",
        "\n",
        "* Power of Hypothesis Test is defined as the probability of not making a type 2 error ie the probability of correctly rejecting $H_0$\n",
        "\n",
        "* There is a trade off if we limit type 1 error then we have an increase in type 2 error. Likewise if we limit type 2 error then we increase type 1 error.\n",
        "\n",
        "* Normally care more abt type 1 error and limit this one over type 2. We do this since it is a more scientific blunder to declare something as true that is not true.\n",
        "\n",
        "* This is why we have a specific value for p to limit the type 1 errors."
      ],
      "metadata": {
        "id": "A43_6N1Pam2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13.2 The Challenge of Multiple Testing\n",
        "\n",
        "* The problem with a ton of data is there is a ton of random chance. Therefore we can get extremely small p values by random luck.\n",
        "\n",
        "* Then we would reject a null hypothesis and commit a type 1 error. Even though it was just random luck.\n",
        "\n",
        "* If we do this enough times over a large data set we can commit a large amount of type 1 errors.\n",
        "\n",
        "* Now if we do this for m null hypothesis the type 1 error rates can add up fast!"
      ],
      "metadata": {
        "id": "lqZ7ea56emZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13.3 The Family-Wise Error Rate\n",
        "\n",
        "* The goal is to do multiple hypothesis testing while controlling the type 1 error rate."
      ],
      "metadata": {
        "id": "D9godGUwfCi5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 13.3.1 What is the family-wise error rate\n",
        "\n",
        "* Can use this equation to control the amount of type 1 errors we make. If we wish to limit the type 1 errors to $ ≤ 1$ then we can do so and see the amount of m hypothesis tests we can perform.\n",
        "\n",
        "* Also can see how many more hypothesis tests you can get by changing the value of the p test threshold. The lower you make it, the more tests that can be performed.\n",
        "\n",
        "* You can also backtrack the FWER to a better value p to a better T statistic."
      ],
      "metadata": {
        "id": "QhP7agjfgzXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 13.3.2 Approaches to Control the Family-Wise Error Rate\n",
        "\n",
        "* Going to go over approaches for different Family Wise Equations.\n"
      ],
      "metadata": {
        "id": "TksglknRjibk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bonferroni Method\n",
        "\n",
        "* Using union operator instead of the intersection operator used in the normal FWER.\n",
        "\n",
        "* The equation equals $α/m$ . This gives us the p value we need to accept for the threshold.\n",
        "\n",
        "* This type of method doesn't involve assuming each method is independent like FWER does.\n",
        "\n",
        "* Other methods can be better tho as Bonferroni can be too conservative causing more type 2 errors than other methods."
      ],
      "metadata": {
        "id": "0ausNv1qll-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Holm's Step Down Procedure\n",
        "\n",
        "* Makes fewer type 2 errors, rejects as many null hypothesis tests, and is preferred to Bonnferroni as it is more powerful.\n",
        "\n",
        "* Always rejects more null hypothesis which is great if it keeps the same amount of type 1 errors, which is does. This way there is less type 2 errors.\n",
        "\n",
        "* Also doesn't imply independence"
      ],
      "metadata": {
        "id": "TrSVm5EqpY65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tukey Method and Scheffe Method\n",
        "\n",
        "* Methods are great when we look at the data and notice it isn't independent\n",
        "\n",
        "* Scheffe method allows for the combination of many group means and testing groups v each other without an extremely large m value using Bonferroni.\n",
        "\n",
        "* Therefore when looking at means and possible independence consider using Scheffe and Turkey"
      ],
      "metadata": {
        "id": "gjP_5uH_r8ur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Trade Off between FWER and Power\n",
        "\n",
        "* Power is defined by the amount of false null hypotheses that we reject over the total number of false null hypotheses.\n",
        "\n",
        "* As m increases the number of multiple testing, the power decreases. Assuming FWER stays the same.\n",
        "\n",
        "* Therefore we must consider changing FWER and allowing for more false positives. This allows more rejections, thus a higher rate of power. We do this at a high value of m if there is a lot of multiple testing."
      ],
      "metadata": {
        "id": "hBX3KSS2uK-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13.4 The False Discovery Rate"
      ],
      "metadata": {
        "id": "yY74dwCWvamn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 13.4.1 Intutuion for the False Discovery Rate\n",
        "\n",
        "* Might want to keep the ratio of false positives/ true positives. Very low instead of keeping false positives set to 1 or 0 when m is large.\n",
        "\n",
        "* FDP is know as the false discovery proportion and it is defined above.\n",
        "\n",
        "* Very diffcult to control the FDP as we don't know which hypothesis are false and which are true.\n",
        "\n",
        "* Instead we should control the false discovery rate. This is $E(V/R)$ where $(V/R) = FDP$, $E$ = False positive, $R$ = True positives.\n",
        "\n",
        "* There is no universal threshold value instead it is dependent on the data analyst and the goal for the data. Along with computing power."
      ],
      "metadata": {
        "id": "1qom_8xavu8E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Benjamin- Hochberg Procedure\n",
        "\n",
        "* Assumes the p values are independent or midly dependent then it guarantees the $FDR ≤ q$. We pick q.\n",
        "\n",
        "* We can't pick our p value ahead of time using this approach. Instead it is data dependent based on the Bejamin- Hochberg Procedure."
      ],
      "metadata": {
        "id": "pAaDCOrFwSvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13.5 Resmaple Approach for to P values and False Discovery Rate\n",
        "\n",
        "* Normally compute p values using a normal , t, $x^2$, or f distribution.\n",
        "\n",
        "* however what if our data is wonky and doesn't fit one of these distributions. How do we calculate the p value from it then?\n",
        "\n",
        "* Can use the fast ability of computers to compute a distribution for the T to calculate p."
      ],
      "metadata": {
        "id": "bOtWwy6A0LPw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 13.5.1 A Resmapling Approach to the P Value\n",
        "\n",
        "* IF we assume the $H_0$ holds and we don't have enough values for a distribution then we can swap values between $X$ and $Y$ since they have the same mean based on $H_0$.\n",
        "\n",
        "* Then compute a p value by comparing the old T statistic verse the new T statistic on the newly permeated data.\n",
        "\n",
        "* Want to do this resmapling method when the data is skewed or a lack of observations are observed.\n",
        "\n",
        "* Basically calculate the T statistic, then for a B in a certain threshold we create a random permutation. Calculate the $T^B$ for that. Do this B times. At the end calculate how many $(∑_{b=1}^B T^b> T)/ B$. This is our p"
      ],
      "metadata": {
        "id": "tjwnHNw60dp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 13.5.2 A Resampling Approach to False Discovery Rate\n",
        "\n",
        "* Can do the above m resampling p values. Taking 13.5.1 and apply this to every p value. Then apply Benjamin-Hochberg Procedure to generate FDR.\n",
        "\n",
        "* OR we can $\\frac {∑_{j=1}^m ∑_{b=1}^B (|T^b|> |T|)} {Bm}$ by making a small asumption on Benjamin-Hochberg using expected value of R to equal R. Then computing the $E(V)$ using resmapling and predicting the values based on their increase resampling of #b#"
      ],
      "metadata": {
        "id": "6ZqfkKKd3m9n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 13.5.3 When are Resampling Approaches Useful\n",
        "\n",
        "* Not a null distribution is available so must create one\n",
        "\n",
        "* There is a distribution available but the assumptions do not hold true for the data. Like the two variables must be so large. Or the data must be standard normal.\n",
        "\n"
      ],
      "metadata": {
        "id": "xqIsgZly5KZT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pDWUPO1V7cMK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}